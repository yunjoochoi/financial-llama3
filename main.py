from llama_index.core.postprocessor import SentenceTransformerRerank
import time
from hugging import HuggingFaceNotebookLogin
from dataset import DataSetter
from embdding_setter import EmbedSettings
from load_llm import LLMLoader
from prompt_template import PromptTemplates
from db import Db
from config import ENCODER_MODEL

from sentence_transformers import SentenceTransformer, util
import torch

# smart reranking í•¨ìˆ˜ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ + ì¤‘ë³µ ê°€ì‚°ì )
def smart_rerank_context(original_response, keyword_response, question, top_k=5):
    model = SentenceTransformer("BAAI/bge-small-en-v1.5")
    query_emb = model.encode(question, convert_to_tensor=True)

    combined_nodes = (original_response.source_nodes if hasattr(original_response, "source_nodes") else []) + \
                     (keyword_response.source_nodes if hasattr(keyword_response, "source_nodes") else [])

    node_texts = list({node.get_text().strip(): node for node in combined_nodes}.keys())
    node_embs = model.encode(node_texts, convert_to_tensor=True)

    scores = util.cos_sim(query_emb, node_embs)[0]

    node_score_map = {}
    for idx, text in enumerate(node_texts):
        base_score = scores[idx].item()
        bonus = 0
        if any(text == node.get_text().strip() for node in original_response.source_nodes) and \
           any(text == node.get_text().strip() for node in keyword_response.source_nodes):
            bonus += 0.2  # âœ… ì—¬ê¸°ì„œ ì¤‘ë³µ ê°€ì‚°ì  0.2ë¡œ ì„¸íŒ… (ì¡°ì • ê°€ëŠ¥)

        node_score_map[text] = base_score + bonus

    sorted_texts = sorted(node_score_map.items(), key=lambda x: x[1], reverse=True)
    final_texts = [text for text, _ in sorted_texts[:top_k]]

    all_nodes_map = {node.get_text().strip(): node for node in combined_nodes}
    final_nodes = [all_nodes_map[text] for text in final_texts if text in all_nodes_map]

    print(f"âœ… ìµœì¢… ì„ íƒëœ context ìˆ˜: {len(final_nodes)}ê°œ")
    return final_nodes


### ----- Main ì‹¤í–‰ -----

print("hugging Login Start...")
HuggingFaceNotebookLogin().login()

print("load PDF Data Start...")
documents = DataSetter().load_dataset()

promptTP = PromptTemplates()
system_prompt = promptTP.get_system_prompt()
query_wrapper_prompt = promptTP.get_query_wrapper_prompt()

print("Setting Embed Model settings...")
settting = EmbedSettings().set_and_get_llama_settings()

print("Setting LLM settings...")
settting.llm = LLMLoader(system_prompt, query_wrapper_prompt).load_llm()

from keyword_extractor import KeywordExtractor
extractor = KeywordExtractor(top_k=6)

print("Setting db Index settings...")
dbIndex = Db(documents).get_index()

print("Setting SentenceTransformerRerank settings...")
rerank = SentenceTransformerRerank(model=ENCODER_MODEL, top_n=5)

print("Setting Query Engine settings...")
query_engine = dbIndex.as_query_engine(similarity_top_k=20, node_postprocessors=[rerank])

# 1. ì‚¬ìš©ì ì§ˆë¬¸
user_query = "í•˜ì´ë‹‰ìŠ¤ 2024 NAND ì„¸ì¼ì¦ˆëŠ”?"

# 2. í‚¤ì›Œë“œ ì¶”ì¶œ
keywords = extractor.extract(user_query)
print("\nâœ… ì¶”ì¶œëœ í‚¤ì›Œë“œ:", keywords)

# 3. í‚¤ì›Œë“œ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„±
keywords_query = " ".join(keywords)
print("âœ… í‚¤ì›Œë“œ ê¸°ë°˜ ì¿¼ë¦¬:", keywords_query)

# 4. ê°ê° ë³„ë„ë¡œ ê²€ìƒ‰
print("\nOriginal Queryë¡œ ê²€ìƒ‰ ì¤‘...")
original_response = query_engine.query(user_query)

print("Keywords Queryë¡œ ê²€ìƒ‰ ì¤‘...")
keyword_response = query_engine.query(keywords_query)

# 5. smart rerank ì ìš©í•´ì„œ ìµœì¢… context ì„ íƒ
final_context_nodes = smart_rerank_context(original_response, keyword_response, user_query, top_k=5
                                           )

# 6. ìµœì í™”ëœ contextë¡œ LLMì— ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
final_context_text = "\n\n".join([node.get_text() for node in final_context_nodes])
print("\nâœ… ìµœì¢… ë‹µë³€ ìƒì„±ì— ì‚¬ìš©ëœ Context:")
print(final_context_text)

final_prompt = f"""
ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ì •í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”:

{final_context_text}

ì§ˆë¬¸: {user_query}
ë‹µë³€:
"""

# 7. LLMì„ ì§ì ‘ í˜¸ì¶œí•´ì„œ ìµœì¢… ë‹µë³€ ìƒì„±
response = settting.llm.complete(final_prompt)

# 8. ìµœì¢… ê²°ê³¼ ì¶œë ¥
print("\nâœ… ìµœì¢… ìµœì í™”ëœ ë‹µë³€:")
print(response.text)

# 9. ì°¸ê³ ë¡œ Original / Keyword ë³„ ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
print("\nğŸ“„ Original Query Search ê²°ê³¼:")
if hasattr(original_response, "source_nodes"):
    for idx, node in enumerate(original_response.source_nodes):
        print(f"[Original {idx+1}]")
else:
    print("No original source nodes found.")

print("\nğŸ“„ Keyword Query Search ê²°ê³¼:")
if hasattr(keyword_response, "source_nodes"):
    for idx, node in enumerate(keyword_response.source_nodes):
        print(f"[Keyword {idx+1}]\n")
else:
    print("No keyword source nodes found.")
